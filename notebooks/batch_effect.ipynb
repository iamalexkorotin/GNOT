{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"..\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "%matplotlib inline \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import gc\n",
    "import random\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from src import distributions\n",
    "from src.tools import unfreeze, freeze\n",
    "from src.tools import weights_init_D\n",
    "from src.tools import fig2data, fig2img\n",
    "from src.guided_samplers import Sampler, PairedSubsetSampler, SubsetGuidedDataset, get_indicies_subset\n",
    "from src.gaussian_utils import generate_data, plot_gaussian, build_dataloader\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import ot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../RNAseq/Splatter/processed_data/\"\n",
    "print(\"dataset_path: \", dataset_path)\n",
    "normcounts = pd.read_csv(dataset_path + 'combine_expression.csv')\n",
    "labels = pd.read_csv(dataset_path + 'combine_labels.csv')\n",
    "domain_labels = pd.read_csv(dataset_path + 'domain_labels.csv')\n",
    "data_set = {'features': normcounts.T.values, 'labels': labels.iloc[:, 0].values,\n",
    "           'accessions': domain_labels.iloc[:, 0].values}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LABELED = 10\n",
    "T_ITERS = 10\n",
    "BATCH_SIZE = 32\n",
    "ะก_SIZE = 2\n",
    "NUM_MODES = 4\n",
    "\n",
    "D_LR, T_LR = 1e-4, 1e-4\n",
    "PLOT_INTERVAL = 100\n",
    "CPKT_INTERVAL = 1000\n",
    "MAX_STEPS = 1001 #increase if you need better results\n",
    "SEED = 0x000001\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "def test_accuracy(classifier, loader, T=None):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.reshape(-1, 657)\n",
    "            if T:\n",
    "                inputs = T(inputs.cuda())\n",
    "            outputs = classifier(inputs.cuda())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.cuda()).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Accuracy of the model on the test inputs: {accuracy}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build ClassGuided Segerstolpe Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common_labels: [0 1 3 4 5 6 7 8]\n",
      "label_mapping: {0: 0, 1: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}\n",
      "source labels: [0 1 2 3 4 5 6 7]  target labels: [0 1 2 3 4 5 6 7]\n",
      "(3329, 657)\n",
      "(2108, 657)\n"
     ]
    }
   ],
   "source": [
    "kwargs = {'num_workers': 0, 'pin_memory': True}\n",
    "\n",
    "source_name = \"TM_baron_mouse_for_segerstolpe\"\n",
    "target_name = \"segerstolpe_human\"\n",
    "domain_to_indices = np.where(data_set['accessions'] == source_name)[0]\n",
    "source_set = {'features': data_set['features'][domain_to_indices], 'labels': data_set['labels'][domain_to_indices], 'accessions': data_set['accessions'][domain_to_indices]}\n",
    "\n",
    "domain_to_indices = np.where(data_set['accessions'] == target_name)[0]\n",
    "target_set = {'features': data_set['features'][domain_to_indices], 'labels': data_set['labels'][domain_to_indices],'accessions': data_set['accessions'][domain_to_indices]}\n",
    "\n",
    "common_labels = np.intersect1d(np.unique(source_set['labels']), np.unique(target_set['labels']))\n",
    "print('common_labels:', common_labels)\n",
    "\n",
    "source_set_filtered_indices = np.isin(source_set['labels'], common_labels)\n",
    "source_set_filtered = {\n",
    "    'features': source_set['features'][source_set_filtered_indices],\n",
    "    'labels': source_set['labels'][source_set_filtered_indices],\n",
    "    'accessions': source_set['accessions'][source_set_filtered_indices],\n",
    "}\n",
    "\n",
    "label_mapping = {label: index for index, label in enumerate(np.unique(source_set_filtered['labels']))}\n",
    "print('label_mapping:', label_mapping)\n",
    "\n",
    "source_set_filtered['labels'] = np.array([label_mapping[label] for label in source_set_filtered['labels']])\n",
    "target_set['labels'] = np.array([label_mapping[label] for label in target_set['labels']])\n",
    "\n",
    "print('source labels:', np.unique(source_set_filtered['labels']), ' target labels:', np.unique(target_set['labels']))\n",
    "\n",
    "test_set_eval = {'features': data_set['features'][domain_to_indices], 'labels': data_set['labels'][domain_to_indices], 'accessions': data_set['accessions'][domain_to_indices]}\n",
    "\n",
    "print(source_set_filtered['features'].shape)\n",
    "print(target_set['features'].shape)\n",
    "\n",
    "source_data = torch.utils.data.TensorDataset(torch.FloatTensor(source_set_filtered['features']), torch.LongTensor(source_set_filtered['labels']))\n",
    "source_loader = torch.utils.data.DataLoader(source_data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, **kwargs)\n",
    "\n",
    "target_data = torch.utils.data.TensorDataset(torch.FloatTensor(target_set['features']), torch.LongTensor(target_set['labels']))\n",
    "target_loader = torch.utils.data.DataLoader(target_data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, **kwargs)\n",
    "target_test_loader = torch.utils.data.DataLoader(target_data, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_classes = torch.tensor(list(range(0,len(np.unique(source_set_filtered['labels'])))))\n",
    "source_labels = {i.item():i.item() for i in source_classes}\n",
    "\n",
    "target_classes = source_classes\n",
    "new_target_labels = source_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_samples, labels, source_class_indicies = get_indicies_subset(source_data, \n",
    "                                                                    new_labels = source_labels, \n",
    "                                                                    classes=len(source_classes), \n",
    "                                                                    subset_classes=source_classes)\n",
    "source_train = TensorDataset(torch.stack(subset_samples), torch.LongTensor(labels))\n",
    "\n",
    "target_subset_samples, target_labels, target_class_indicies = get_indicies_subset(target_data, \n",
    "                                                                                  new_labels = new_target_labels, \n",
    "                                                                                  classes=len(target_classes), \n",
    "                                                                                  subset_classes=target_classes)\n",
    "target_train = TensorDataset(torch.stack(target_subset_samples), torch.LongTensor(target_labels))\n",
    "\n",
    "train_set = SubsetGuidedDataset(source_train, target_train, \n",
    "                                num_labeled=NUM_LABELED, \n",
    "                                in_indicies = source_class_indicies, \n",
    "                                out_indicies = target_class_indicies)\n",
    "\n",
    "full_set = SubsetGuidedDataset(source_train, target_train, \n",
    "                               num_labeled='all', \n",
    "                               in_indicies = source_class_indicies, \n",
    "                               out_indicies = target_class_indicies)\n",
    "T_XY_sampler = PairedSubsetSampler(train_set, subsetsize=ะก_SIZE)\n",
    "D_XY_sampler = PairedSubsetSampler(full_set, subsetsize=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "T = FeedForward(657, 512, 657).cuda()\n",
    "D = FeedForward(657, 1024, 1).cuda()\n",
    "T_opt = torch.optim.Adam(T.parameters(), lr=T_LR, weight_decay=1e-10)\n",
    "D_opt = torch.optim.Adam(D.parameters(), lr=D_LR, weight_decay=1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Oracle Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier(657, 8).cuda()\n",
    "classifier_opt = torch.optim.Adam(classifier.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [10/65], Loss: 1.8696\n",
      "Accuracy of the model on the test inputs: 21.537001897533205%\n",
      "Epoch [1/10], Step [20/65], Loss: 1.8387\n",
      "Accuracy of the model on the test inputs: 34.58254269449716%\n",
      "Epoch [1/10], Step [30/65], Loss: 1.7604\n",
      "Accuracy of the model on the test inputs: 47.01138519924098%\n",
      "Epoch [1/10], Step [40/65], Loss: 1.5038\n",
      "Accuracy of the model on the test inputs: 58.96584440227704%\n",
      "Epoch [1/10], Step [50/65], Loss: 1.4988\n",
      "Accuracy of the model on the test inputs: 64.04174573055029%\n",
      "Epoch [1/10], Step [60/65], Loss: 1.0741\n",
      "Accuracy of the model on the test inputs: 66.93548387096774%\n",
      "Epoch [2/10], Step [10/65], Loss: 1.1407\n",
      "Accuracy of the model on the test inputs: 69.87666034155598%\n",
      "Epoch [2/10], Step [20/65], Loss: 1.1629\n",
      "Accuracy of the model on the test inputs: 72.34345351043643%\n",
      "Epoch [2/10], Step [30/65], Loss: 0.8445\n",
      "Accuracy of the model on the test inputs: 74.47817836812145%\n",
      "Epoch [2/10], Step [40/65], Loss: 0.9549\n",
      "Accuracy of the model on the test inputs: 76.18595825426945%\n",
      "Epoch [2/10], Step [50/65], Loss: 0.8410\n",
      "Accuracy of the model on the test inputs: 77.41935483870968%\n",
      "Epoch [2/10], Step [60/65], Loss: 0.9652\n",
      "Accuracy of the model on the test inputs: 78.98481973434535%\n",
      "Epoch [3/10], Step [10/65], Loss: 0.7072\n",
      "Accuracy of the model on the test inputs: 80.1707779886148%\n",
      "Epoch [3/10], Step [20/65], Loss: 0.7008\n",
      "Accuracy of the model on the test inputs: 81.59392789373814%\n",
      "Epoch [3/10], Step [30/65], Loss: 0.5785\n",
      "Accuracy of the model on the test inputs: 82.73244781783681%\n",
      "Epoch [3/10], Step [40/65], Loss: 0.7702\n",
      "Accuracy of the model on the test inputs: 83.91840607210627%\n",
      "Epoch [3/10], Step [50/65], Loss: 0.8681\n",
      "Accuracy of the model on the test inputs: 85.10436432637572%\n",
      "Epoch [3/10], Step [60/65], Loss: 0.7358\n",
      "Accuracy of the model on the test inputs: 86.19544592030361%\n",
      "Epoch [4/10], Step [10/65], Loss: 0.5972\n",
      "Accuracy of the model on the test inputs: 87.5237191650854%\n",
      "Epoch [4/10], Step [20/65], Loss: 0.6065\n",
      "Accuracy of the model on the test inputs: 88.09297912713473%\n",
      "Epoch [4/10], Step [30/65], Loss: 0.4944\n",
      "Accuracy of the model on the test inputs: 88.42504743833017%\n",
      "Epoch [4/10], Step [40/65], Loss: 0.3861\n",
      "Accuracy of the model on the test inputs: 88.85199240986718%\n",
      "Epoch [4/10], Step [50/65], Loss: 0.5248\n",
      "Accuracy of the model on the test inputs: 89.56356736242884%\n",
      "Epoch [4/10], Step [60/65], Loss: 0.4050\n",
      "Accuracy of the model on the test inputs: 90.0853889943074%\n",
      "Epoch [5/10], Step [10/65], Loss: 0.4078\n",
      "Accuracy of the model on the test inputs: 90.55977229601518%\n",
      "Epoch [5/10], Step [20/65], Loss: 0.3856\n",
      "Accuracy of the model on the test inputs: 91.12903225806451%\n",
      "Epoch [5/10], Step [30/65], Loss: 0.3300\n",
      "Accuracy of the model on the test inputs: 91.74573055028463%\n",
      "Epoch [5/10], Step [40/65], Loss: 0.4249\n",
      "Accuracy of the model on the test inputs: 92.26755218216319%\n",
      "Epoch [5/10], Step [50/65], Loss: 0.4459\n",
      "Accuracy of the model on the test inputs: 92.88425047438331%\n",
      "Epoch [5/10], Step [60/65], Loss: 0.3141\n",
      "Accuracy of the model on the test inputs: 93.69070208728652%\n",
      "Epoch [6/10], Step [10/65], Loss: 0.3294\n",
      "Accuracy of the model on the test inputs: 94.25996204933587%\n",
      "Epoch [6/10], Step [20/65], Loss: 0.3328\n",
      "Accuracy of the model on the test inputs: 94.59203036053131%\n",
      "Epoch [6/10], Step [30/65], Loss: 0.2911\n",
      "Accuracy of the model on the test inputs: 95.11385199240986%\n",
      "Epoch [6/10], Step [40/65], Loss: 0.3655\n",
      "Accuracy of the model on the test inputs: 95.54079696394687%\n",
      "Epoch [6/10], Step [50/65], Loss: 0.2667\n",
      "Accuracy of the model on the test inputs: 96.06261859582543%\n",
      "Epoch [6/10], Step [60/65], Loss: 0.3515\n",
      "Accuracy of the model on the test inputs: 96.20493358633776%\n",
      "Epoch [7/10], Step [10/65], Loss: 0.3357\n",
      "Accuracy of the model on the test inputs: 96.7741935483871%\n",
      "Epoch [7/10], Step [20/65], Loss: 0.3380\n",
      "Accuracy of the model on the test inputs: 96.96394686907021%\n",
      "Epoch [7/10], Step [30/65], Loss: 0.1913\n",
      "Accuracy of the model on the test inputs: 97.34345351043643%\n",
      "Epoch [7/10], Step [40/65], Loss: 0.1848\n",
      "Accuracy of the model on the test inputs: 97.58064516129032%\n",
      "Epoch [7/10], Step [50/65], Loss: 0.2891\n",
      "Accuracy of the model on the test inputs: 97.81783681214421%\n",
      "Epoch [7/10], Step [60/65], Loss: 0.3726\n",
      "Accuracy of the model on the test inputs: 97.91271347248576%\n",
      "Epoch [8/10], Step [10/65], Loss: 0.3760\n",
      "Accuracy of the model on the test inputs: 98.10246679316889%\n",
      "Epoch [8/10], Step [20/65], Loss: 0.2189\n",
      "Accuracy of the model on the test inputs: 98.19734345351044%\n",
      "Epoch [8/10], Step [30/65], Loss: 0.2651\n",
      "Accuracy of the model on the test inputs: 98.24478178368122%\n",
      "Epoch [8/10], Step [40/65], Loss: 0.1854\n",
      "Accuracy of the model on the test inputs: 98.33965844402277%\n",
      "Epoch [8/10], Step [50/65], Loss: 0.2281\n",
      "Accuracy of the model on the test inputs: 98.4819734345351%\n",
      "Epoch [8/10], Step [60/65], Loss: 0.3008\n",
      "Accuracy of the model on the test inputs: 98.57685009487666%\n",
      "Epoch [9/10], Step [10/65], Loss: 0.1573\n",
      "Accuracy of the model on the test inputs: 98.9089184060721%\n",
      "Epoch [9/10], Step [20/65], Loss: 0.2627\n",
      "Accuracy of the model on the test inputs: 98.95635673624288%\n",
      "Epoch [9/10], Step [30/65], Loss: 0.1612\n",
      "Accuracy of the model on the test inputs: 98.95635673624288%\n",
      "Epoch [9/10], Step [40/65], Loss: 0.2309\n",
      "Accuracy of the model on the test inputs: 99.05123339658444%\n",
      "Epoch [9/10], Step [50/65], Loss: 0.1893\n",
      "Accuracy of the model on the test inputs: 99.05123339658444%\n",
      "Epoch [9/10], Step [60/65], Loss: 0.2282\n",
      "Accuracy of the model on the test inputs: 99.05123339658444%\n",
      "Epoch [10/10], Step [10/65], Loss: 0.1862\n",
      "Accuracy of the model on the test inputs: 99.09867172675521%\n",
      "Epoch [10/10], Step [20/65], Loss: 0.1416\n",
      "Accuracy of the model on the test inputs: 99.14611005692599%\n",
      "Epoch [10/10], Step [30/65], Loss: 0.1553\n",
      "Accuracy of the model on the test inputs: 99.19354838709677%\n",
      "Epoch [10/10], Step [40/65], Loss: 0.1768\n",
      "Accuracy of the model on the test inputs: 99.24098671726755%\n",
      "Epoch [10/10], Step [50/65], Loss: 0.2097\n",
      "Accuracy of the model on the test inputs: 99.19354838709677%\n",
      "Epoch [10/10], Step [60/65], Loss: 0.1540\n",
      "Accuracy of the model on the test inputs: 99.3358633776091%\n"
     ]
    }
   ],
   "source": [
    "total_step = len(target_loader)\n",
    "for epoch in range(10):\n",
    "    for i, (inputs, labels) in enumerate(target_loader):\n",
    "        inputs = inputs.reshape(-1, 657)\n",
    "        outputs = classifier(inputs.cuda())\n",
    "        loss = criterion(outputs, labels.cuda())\n",
    "        classifier_opt.zero_grad()\n",
    "        loss.backward()\n",
    "        classifier_opt.step()\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{10}], Step [{i+1}/{total_step}], Loss: {loss.item():.4f}\")\n",
    "            with torch.no_grad():\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                for inputs, labels in target_test_loader:\n",
    "                    inputs = inputs.reshape(-1, 657)\n",
    "                    outputs = classifier(inputs.cuda())\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels.cuda()).sum().item()\n",
    "\n",
    "                print(f\"Accuracy of the model on the test inputs: {100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy on the source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test inputs: 63.01081730769231%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63.01081730769231"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy(classifier, source_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb5a95a742845b5ad4f3f5b30c21f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 33.0207405090332\n",
      "step: 0\n",
      "Accuracy of the model on the test inputs: 7.782451923076923%\n",
      "Loss: 11.21495246887207\n",
      "step: 100\n",
      "Accuracy of the model on the test inputs: 83.50360576923077%\n",
      "Loss: 11.319890022277832\n",
      "step: 200\n",
      "Accuracy of the model on the test inputs: 90.05408653846153%\n",
      "Loss: 12.746994972229004\n",
      "step: 300\n",
      "Accuracy of the model on the test inputs: 91.64663461538461%\n",
      "Loss: 11.459309577941895\n",
      "step: 400\n",
      "Accuracy of the model on the test inputs: 88.64182692307692%\n",
      "Loss: 11.525487899780273\n",
      "step: 500\n",
      "Accuracy of the model on the test inputs: 92.51802884615384%\n",
      "Loss: 12.656315803527832\n",
      "step: 600\n",
      "Accuracy of the model on the test inputs: 90.80528846153847%\n",
      "Loss: 12.93928337097168\n",
      "step: 700\n",
      "Accuracy of the model on the test inputs: 90.53485576923077%\n",
      "Loss: 13.689186096191406\n",
      "step: 800\n",
      "Accuracy of the model on the test inputs: 91.22596153846153%\n",
      "Loss: 11.785080909729004\n",
      "step: 900\n",
      "Accuracy of the model on the test inputs: 90.625%\n",
      "Loss: 13.19101333618164\n",
      "step: 1000\n",
      "Accuracy of the model on the test inputs: 87.83052884615384%\n"
     ]
    }
   ],
   "source": [
    "for step in tqdm(range(MAX_STEPS)):\n",
    "    unfreeze(T); freeze(D)\n",
    "    for t_iter in range(T_ITERS): \n",
    "        T_opt.zero_grad()\n",
    "        X, Y = T_XY_sampler.sample(BATCH_SIZE)\n",
    "        T_X = T(X.flatten(start_dim=0, end_dim=1)).permute(1,0).reshape(657, -1, ะก_SIZE).permute(1,2,0)    \n",
    "        T_var = .5 * torch.cdist(T_X, T_X).mean() * ะก_SIZE / (ะก_SIZE -1)\n",
    "        cost = (Y-T_X).norm(dim=2).mean()\n",
    "        T_loss = cost - T_var - D(T_X.flatten(start_dim=0, end_dim=1)).mean()\n",
    "        T_loss.backward(); T_opt.step()\n",
    "        \n",
    "    del T_X, X, Y, T_var; gc.collect(); torch.cuda.empty_cache() \n",
    "\n",
    "    freeze(T); unfreeze(D)\n",
    "    X, _ = T_XY_sampler.sample(BATCH_SIZE)\n",
    "    _, Y = D_XY_sampler.sample(BATCH_SIZE)\n",
    "    with torch.no_grad():\n",
    "        T_X = T(X.flatten(start_dim=0, end_dim=1)) \n",
    "    Y = torch.squeeze(Y)\n",
    "    D_opt.zero_grad()\n",
    "    D_loss = D(T_X).mean() - D(Y).mean()\n",
    "    D_loss.backward(); D_opt.step();\n",
    "    \n",
    "    if step % PLOT_INTERVAL == 0:\n",
    "        print('Loss:', T_loss.item())\n",
    "        print('step:', step)\n",
    "        _ = test_accuracy(classifier, source_loader, T)\n",
    "    del D_loss, Y, X, T_X; gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the Best Discrete Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_list_subset = [source_loader.dataset[n][0].numpy().flatten() for n in range(len(source_loader.dataset))]\n",
    "source_labels_subset = [source_loader.dataset[n][1] for n in range(len(source_loader.dataset))]\n",
    "\n",
    "Xs = np.array(source_list_subset)\n",
    "ys = np.array(source_labels_subset)\n",
    "\n",
    "target_list_subset = [target_loader.dataset[n][0].numpy().flatten() for n in range(len(target_loader.dataset))]\n",
    "target_labels_subset = [target_loader.dataset[n][1] for n in range(len(target_loader.dataset))]\n",
    "\n",
    "Xs = np.array(source_list_subset)\n",
    "ys = np.array(source_labels_subset)\n",
    "Xt = np.array(target_list_subset)\n",
    "yt = np.array(target_labels_subset)\n",
    "\n",
    "unique_classes = np.unique(yt)\n",
    "mask = np.full(yt.size, False)\n",
    "\n",
    "# Set 10 samples per class to True in the mask\n",
    "for c in unique_classes:\n",
    "    class_indices = np.where(yt == c)[0]\n",
    "    selected_indices = np.random.choice(class_indices, NUM_LABELED, replace=False)\n",
    "    mask[selected_indices] = True\n",
    "\n",
    "# Set the non-selected samples to -1\n",
    "yt[~mask] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy before adaptation:\n",
      "Accuracy of the model on the test inputs: 62.98076923076923%\n",
      "Regularizetion reg_cl: 2\n",
      "Regularizetion reg_e: 2\n",
      "--------------------------\n",
      "EMD\n",
      "Accuracy of the model on the test inputs: 50.435566236106936%\n",
      "--------------------------\n",
      "Sinkhorn\n",
      "Accuracy of the model on the test inputs: 6.848903574647041%\n",
      "--------------------------\n",
      "SinkhornLpl1\n",
      "Accuracy of the model on the test inputs: 4.025232802643436%\n",
      "--------------------------\n",
      "SinkhornL1l2\n",
      "Accuracy of the model on the test inputs: 17.482727545809553%\n",
      "--------------------------\n",
      "MapOT\n",
      "Accuracy of the model on the test inputs: 42.234905376990085%\n",
      "--------------------------\n",
      "Regularizetion reg_cl: 5\n",
      "Regularizetion reg_e: 2\n",
      "--------------------------\n",
      "EMD\n",
      "Accuracy of the model on the test inputs: 50.435566236106936%\n",
      "--------------------------\n",
      "Sinkhorn\n",
      "Accuracy of the model on the test inputs: 6.848903574647041%\n",
      "--------------------------\n",
      "SinkhornLpl1\n",
      "Accuracy of the model on the test inputs: 3.4244517873235205%\n",
      "--------------------------\n",
      "SinkhornL1l2\n",
      "Accuracy of the model on the test inputs: 17.482727545809553%\n",
      "--------------------------\n",
      "MapOT\n",
      "Accuracy of the model on the test inputs: 42.234905376990085%\n",
      "--------------------------\n",
      "Regularizetion reg_cl: 10\n",
      "Regularizetion reg_e: 2\n",
      "--------------------------\n",
      "EMD\n",
      "Accuracy of the model on the test inputs: 50.435566236106936%\n",
      "--------------------------\n",
      "Sinkhorn\n",
      "Accuracy of the model on the test inputs: 6.848903574647041%\n",
      "--------------------------\n",
      "SinkhornLpl1\n",
      "Accuracy of the model on the test inputs: 3.4244517873235205%\n",
      "--------------------------\n",
      "SinkhornL1l2\n",
      "Accuracy of the model on the test inputs: 17.482727545809553%\n",
      "--------------------------\n",
      "MapOT\n",
      "Accuracy of the model on the test inputs: 42.234905376990085%\n",
      "--------------------------\n",
      "Regularizetion reg_cl: 100\n",
      "Regularizetion reg_e: 2\n",
      "--------------------------\n",
      "EMD\n",
      "Accuracy of the model on the test inputs: 50.435566236106936%\n",
      "--------------------------\n",
      "Sinkhorn\n",
      "Accuracy of the model on the test inputs: 6.848903574647041%\n",
      "--------------------------\n",
      "SinkhornLpl1\n",
      "Accuracy of the model on the test inputs: 3.4244517873235205%\n",
      "--------------------------\n",
      "SinkhornL1l2\n",
      "Accuracy of the model on the test inputs: 17.542805647341545%\n",
      "--------------------------\n",
      "MapOT\n",
      "Accuracy of the model on the test inputs: 42.234905376990085%\n",
      "--------------------------\n",
      "Regularizetion reg_cl: 2\n",
      "Regularizetion reg_e: 5\n",
      "--------------------------\n",
      "EMD\n",
      "Accuracy of the model on the test inputs: 50.435566236106936%\n",
      "--------------------------\n",
      "Sinkhorn\n",
      "Accuracy of the model on the test inputs: 19.2850705917693%\n",
      "--------------------------\n",
      "SinkhornLpl1\n",
      "Accuracy of the model on the test inputs: 19.2850705917693%\n",
      "--------------------------\n",
      "SinkhornL1l2\n",
      "Accuracy of the model on the test inputs: 20.666866927005106%\n",
      "--------------------------\n",
      "MapOT\n",
      "Accuracy of the model on the test inputs: 42.234905376990085%\n",
      "--------------------------\n",
      "Regularizetion reg_cl: 5\n",
      "Regularizetion reg_e: 5\n",
      "--------------------------\n",
      "EMD\n",
      "Accuracy of the model on the test inputs: 50.435566236106936%\n",
      "--------------------------\n",
      "Sinkhorn\n",
      "Accuracy of the model on the test inputs: 19.2850705917693%\n",
      "--------------------------\n",
      "SinkhornLpl1\n",
      "Accuracy of the model on the test inputs: 19.2850705917693%\n",
      "--------------------------\n",
      "SinkhornL1l2\n",
      "Accuracy of the model on the test inputs: 20.366476419345148%\n",
      "--------------------------\n",
      "MapOT\n",
      "Accuracy of the model on the test inputs: 42.234905376990085%\n",
      "--------------------------\n",
      "Regularizetion reg_cl: 10\n",
      "Regularizetion reg_e: 5\n",
      "--------------------------\n",
      "EMD\n",
      "Accuracy of the model on the test inputs: 50.435566236106936%\n",
      "--------------------------\n",
      "Sinkhorn\n",
      "Accuracy of the model on the test inputs: 19.2850705917693%\n",
      "--------------------------\n",
      "SinkhornLpl1\n",
      "Accuracy of the model on the test inputs: 19.044758185641335%\n",
      "--------------------------\n",
      "SinkhornL1l2\n",
      "Accuracy of the model on the test inputs: 20.63682787623911%\n",
      "--------------------------\n",
      "MapOT\n",
      "Accuracy of the model on the test inputs: 42.234905376990085%\n",
      "--------------------------\n",
      "Regularizetion reg_cl: 100\n",
      "Regularizetion reg_e: 5\n",
      "--------------------------\n",
      "EMD\n",
      "Accuracy of the model on the test inputs: 50.435566236106936%\n",
      "--------------------------\n",
      "Sinkhorn\n",
      "Accuracy of the model on the test inputs: 19.2850705917693%\n",
      "--------------------------\n",
      "SinkhornLpl1\n",
      "Accuracy of the model on the test inputs: 3.4244517873235205%\n",
      "--------------------------\n",
      "SinkhornL1l2\n",
      "Accuracy of the model on the test inputs: 17.63292279963953%\n",
      "--------------------------\n",
      "MapOT\n",
      "Accuracy of the model on the test inputs: 42.234905376990085%\n",
      "--------------------------\n",
      "Regularizetion reg_cl: 2\n",
      "Regularizetion reg_e: 10\n",
      "--------------------------\n",
      "EMD\n",
      "Accuracy of the model on the test inputs: 50.435566236106936%\n",
      "--------------------------\n",
      "Sinkhorn\n",
      "Accuracy of the model on the test inputs: 19.34514869330129%\n",
      "--------------------------\n",
      "SinkhornLpl1\n",
      "Accuracy of the model on the test inputs: 19.34514869330129%\n",
      "--------------------------\n",
      "SinkhornL1l2\n",
      "Accuracy of the model on the test inputs: 19.615500150195253%\n",
      "--------------------------\n",
      "MapOT\n",
      "Accuracy of the model on the test inputs: 42.234905376990085%\n",
      "--------------------------\n",
      "Regularizetion reg_cl: 5\n",
      "Regularizetion reg_e: 10\n",
      "--------------------------\n",
      "EMD\n",
      "Accuracy of the model on the test inputs: 50.435566236106936%\n",
      "--------------------------\n",
      "Sinkhorn\n",
      "Accuracy of the model on the test inputs: 19.34514869330129%\n",
      "--------------------------\n",
      "SinkhornLpl1\n",
      "Accuracy of the model on the test inputs: 19.34514869330129%\n",
      "--------------------------\n",
      "SinkhornL1l2\n",
      "Accuracy of the model on the test inputs: 19.615500150195253%\n",
      "--------------------------\n",
      "MapOT\n",
      "Accuracy of the model on the test inputs: 42.234905376990085%\n",
      "--------------------------\n",
      "Regularizetion reg_cl: 10\n",
      "Regularizetion reg_e: 10\n",
      "--------------------------\n",
      "EMD\n",
      "Accuracy of the model on the test inputs: 50.435566236106936%\n",
      "--------------------------\n",
      "Sinkhorn\n",
      "Accuracy of the model on the test inputs: 19.34514869330129%\n",
      "--------------------------\n",
      "SinkhornLpl1\n",
      "Accuracy of the model on the test inputs: 19.34514869330129%\n",
      "--------------------------\n",
      "SinkhornL1l2\n",
      "Accuracy of the model on the test inputs: 19.555422048663264%\n",
      "--------------------------\n",
      "MapOT\n",
      "Accuracy of the model on the test inputs: 42.234905376990085%\n",
      "--------------------------\n",
      "Regularizetion reg_cl: 100\n",
      "Regularizetion reg_e: 10\n",
      "--------------------------\n",
      "EMD\n",
      "Accuracy of the model on the test inputs: 50.435566236106936%\n",
      "--------------------------\n",
      "Sinkhorn\n",
      "Accuracy of the model on the test inputs: 19.34514869330129%\n",
      "--------------------------\n",
      "SinkhornLpl1\n",
      "Accuracy of the model on the test inputs: 3.4244517873235205%\n",
      "--------------------------\n",
      "SinkhornL1l2\n",
      "Accuracy of the model on the test inputs: 19.315109642535297%\n",
      "--------------------------\n",
      "MapOT\n",
      "Accuracy of the model on the test inputs: 42.234905376990085%\n",
      "--------------------------\n",
      "Regularizetion reg_cl: 2\n",
      "Regularizetion reg_e: 100\n",
      "--------------------------\n",
      "EMD\n",
      "Accuracy of the model on the test inputs: 50.435566236106936%\n",
      "--------------------------\n",
      "Sinkhorn\n",
      "Accuracy of the model on the test inputs: 37.24842294983478%\n",
      "--------------------------\n",
      "SinkhornLpl1\n",
      "Accuracy of the model on the test inputs: 37.338540102132775%\n",
      "--------------------------\n",
      "SinkhornL1l2\n",
      "Accuracy of the model on the test inputs: 37.21838389906879%\n",
      "--------------------------\n",
      "MapOT\n",
      "Accuracy of the model on the test inputs: 42.234905376990085%\n",
      "--------------------------\n",
      "Regularizetion reg_cl: 5\n",
      "Regularizetion reg_e: 100\n",
      "--------------------------\n",
      "EMD\n",
      "Accuracy of the model on the test inputs: 50.435566236106936%\n",
      "--------------------------\n",
      "Sinkhorn\n",
      "Accuracy of the model on the test inputs: 37.24842294983478%\n",
      "--------------------------\n",
      "SinkhornLpl1\n",
      "Accuracy of the model on the test inputs: 37.42865725443076%\n",
      "--------------------------\n",
      "SinkhornL1l2\n",
      "Accuracy of the model on the test inputs: 37.21838389906879%\n",
      "--------------------------\n",
      "MapOT\n",
      "Accuracy of the model on the test inputs: 42.234905376990085%\n",
      "--------------------------\n",
      "Regularizetion reg_cl: 10\n",
      "Regularizetion reg_e: 100\n",
      "--------------------------\n",
      "EMD\n",
      "Accuracy of the model on the test inputs: 50.435566236106936%\n",
      "--------------------------\n",
      "Sinkhorn\n",
      "Accuracy of the model on the test inputs: 37.24842294983478%\n",
      "--------------------------\n",
      "SinkhornLpl1\n",
      "Accuracy of the model on the test inputs: 37.48873535596275%\n",
      "--------------------------\n",
      "SinkhornL1l2\n",
      "Accuracy of the model on the test inputs: 37.21838389906879%\n",
      "--------------------------\n",
      "MapOT\n",
      "Accuracy of the model on the test inputs: 42.234905376990085%\n",
      "--------------------------\n",
      "Regularizetion reg_cl: 100\n",
      "Regularizetion reg_e: 100\n",
      "--------------------------\n",
      "EMD\n",
      "Accuracy of the model on the test inputs: 50.435566236106936%\n",
      "--------------------------\n",
      "Sinkhorn\n",
      "Accuracy of the model on the test inputs: 37.24842294983478%\n",
      "--------------------------\n",
      "SinkhornLpl1\n",
      "Accuracy of the model on the test inputs: 38.630219285070595%\n",
      "--------------------------\n",
      "SinkhornL1l2\n",
      "Accuracy of the model on the test inputs: 37.21838389906879%\n",
      "--------------------------\n",
      "MapOT\n",
      "Accuracy of the model on the test inputs: 42.234905376990085%\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Model Accuracy before adaptation:')\n",
    "test_accuracy(classifier, source_loader)\n",
    "\n",
    "for reg_e in [0.1, 1, 2, 5, 10, 100]:\n",
    "    for reg in [0.1, 1, 2, 5, 10, 100]:\n",
    "        print('Regularizetion reg_cl:',reg)\n",
    "        print('Regularizetion reg_e:', reg_e)\n",
    "        print('--------------------------')\n",
    "        transports = {'EMD':ot.da.EMDTransport(), \n",
    "                      'Sinkhorn':ot.da.SinkhornTransport(reg_e=reg_e, verbose=False), \n",
    "                      'SinkhornLpl1':ot.da.SinkhornLpl1Transport(reg_e=reg_e, reg_cl=reg, verbose=False),\n",
    "                      'SinkhornL1l2':ot.da.SinkhornL1l2Transport(reg_e=reg_e, reg_cl=reg, verbose=False),\n",
    "                      'MapOT':ot.da.MappingTransport(kernel=\"linear\", mu=1, eta=1e-0, bias=True, max_iter=20, verbose=False)\n",
    "                     }\n",
    "\n",
    "        accs = []\n",
    "        for ot_name in transports:\n",
    "            ot_mapping = transports[ot_name]\n",
    "            ot_mapping.fit(Xs=Xs[:], \n",
    "                           Xt=Xt[:],\n",
    "                           ys=ys, \n",
    "                           yt=yt)\n",
    "\n",
    "            # for out of source samples, transform applies the linear mapping\n",
    "            X_test_mapped_ = ot_mapping.transform(Xs=Xs)\n",
    "            X_test_mapped = TensorDataset(torch.FloatTensor(X_test_mapped_), torch.LongTensor(ys)) \n",
    "            X_test_mapped = DataLoader(X_test_mapped, batch_size=100)\n",
    "            print(ot_name)\n",
    "            accs.append(test_accuracy(classifier,X_test_mapped))\n",
    "            print('--------------------------')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
