{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import gc\n",
    "\n",
    "from src import distributions\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# NOT networks\n",
    "from src.resnet2 import ResNet_D\n",
    "from src.unet import UNet\n",
    "\n",
    "from src.tools import unfreeze, freeze\n",
    "from src.tools import weights_init_D\n",
    "from src.tools_paired import load_paired_dataset, get_pushed_loader_stats, get_pushed_loader_metrics\n",
    "from src.fid_score import calculate_frechet_distance\n",
    "from src.plotters import plot_random_paired_images, plot_images\n",
    "from src.u2net import U2NET\n",
    "from src.losses import VGGPerceptualLoss as VGGLoss\n",
    "\n",
    "from copy import deepcopy\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import wandb\n",
    "from src.tools import fig2data, fig2img # for wandb\n",
    "\n",
    "# This needed to use dataloaders for some datasets\n",
    "from PIL import PngImagePlugin\n",
    "LARGE_ENOUGH_NUMBER = 100\n",
    "PngImagePlugin.MAX_TEXT_CHUNK = LARGE_ENOUGH_NUMBER * (1024**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "DEVICE_IDS = [0]\n",
    "\n",
    "# DATASET, DATASET_PATH, REVERSE = 'comic_faces_v1', '../datasets/face2comics_v1.0.0_by_Sxela', False\n",
    "DATASET, DATASET_PATH, REVERSE = 'celeba_mask', '../datasets/CelebAMask-HQ', False\n",
    "#DATASET, DATASET_PATH, REVERSE = 'edges2shoes', '../datasets/Edges2Shoes', False\n",
    "\n",
    "T_TYPE = 'U2Net'  # 'Unet_pix2pix' # 'UNet' # or  ('ResNet_pix2pix' - not implemented)\n",
    "D_TYPE = 'ResNet'  # or 'ResNet_pix2pix' - DOES NOT WORK WELL (it is actually not a resnet:)\n",
    "\n",
    "# These three work only for pix2pix networks\n",
    "T_DROPOUT = False\n",
    "T_NORM = 'batch' # 'instance' or 'none'\n",
    "\n",
    "# Works only for ResNet_D\n",
    "D_DROPOUT = False\n",
    "\n",
    "# For ResNet_pix2pix it uses the given layer. For our ResNet_D uses the batchnorm/none.\n",
    "D_NORM = 'none' # 'instance' or 'none'\n",
    "GP = 10\n",
    "LAMBDA = 0.1\n",
    "T_ITERS = 10\n",
    "D_LR, T_LR = 0.0001, 0.0001\n",
    "IMG_SIZE = 256\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "CONDITIONAL = False # Test conditional NOT (not needed anymore)\n",
    "NOT = True # Train Neural optimal transport or pure regression\n",
    "\n",
    "PLOT_INTERVAL = 1000\n",
    "COST ='vgg' #'mse' # 'mae' # 'vgg'\n",
    "CPKT_INTERVAL = 5000\n",
    "MAX_STEPS = 50001\n",
    "SEED = 0x000000\n",
    "\n",
    "# EMAS = [0.99, 0.999, 0.9999]\n",
    "# EMA_START = 70000\n",
    "\n",
    "CONTINUE = -1\n",
    "\n",
    "EXP_NAME = f'NOT_ours_{DATASET}_T{T_ITERS}_{COST}_{IMG_SIZE}_{T_TYPE}_{D_TYPE}_{BATCH_SIZE}_PixelNorm'\n",
    "OUTPUT_PATH = '../checkpoints/{}/gnot/{}_{}_{}_{}_{}_{}_{}_{}/'.format(COST, DATASET, IMG_SIZE, NOT, CONDITIONAL, T_TYPE, D_TYPE, BATCH_SIZE, 'PixelNorm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    DATASET=DATASET,\n",
    "    T_TYPE=T_TYPE, D_TYPE=D_TYPE,\n",
    "    T_ITERS=T_ITERS,\n",
    "    T_DROPOUT=T_DROPOUT, D_DROPOUT=D_DROPOUT,\n",
    "    D_LR=D_LR, T_LR=T_LR,\n",
    "    BATCH_SIZE=BATCH_SIZE,\n",
    "    CONDITIONAL=CONDITIONAL,\n",
    "    NOT=NOT, COST=COST\n",
    ")\n",
    "\n",
    "assert not ((not NOT) and CONDITIONAL)\n",
    "FID_EPOCHS = 50\n",
    "    \n",
    "assert torch.cuda.is_available()\n",
    "torch.cuda.set_device(f'cuda:{DEVICE_IDS[0]}')\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "if COST == 'vgg':\n",
    "    vgg_loss = VGGLoss().cuda()\n",
    "\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data stats for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = '../stats/{}_{}_{}_test.json'.format(DATASET, IMG_SIZE, REVERSE)\n",
    "# with open(filename, 'r') as fp:\n",
    "#     data_stats = json.load(fp)\n",
    "#     mu_data, sigma_data = data_stats['mu'], data_stats['sigma']\n",
    "# del data_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Samplers (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "XY_sampler, XY_test_sampler = load_paired_dataset(DATASET, DATASET_PATH, img_size=IMG_SIZE, reverse=REVERSE)\n",
    "XY_sampler_plt, XY_test_sampler_plt = XY_sampler, XY_test_sampler\n",
    "    \n",
    "torch.cuda.empty_cache(); gc.collect()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_norm_layer = get_norm_layer(T_NORM)\n",
    "D_norm_layer = get_norm_layer(D_NORM)\n",
    "\n",
    "if D_TYPE == 'ResNet':\n",
    "    D = ResNet_D(IMG_SIZE, nc=3 if not CONDITIONAL else 6, bn=D_NORM != 'none', use_dropout=D_DROPOUT).cuda()\n",
    "    D.apply(weights_init_D)\n",
    "elif D_TYPE == 'ResNet_pix2pix':\n",
    "    D = NLayerDiscriminator(\n",
    "        3 if not CONDITIONAL else 6, n_layers=3,\n",
    "        norm_layer=D_norm_layer).cuda()\n",
    "    init_weights(D)\n",
    "else:\n",
    "    raise NotImplementedError('Unknown D_TYPE: {}'.format(D_TYPE))\n",
    "\n",
    "if T_TYPE == 'UNet':\n",
    "    T = UNet(3, 3, base_factor=48).cuda()\n",
    "elif T_TYPE == 'Unet_pix2pix':\n",
    "    T = UnetGenerator(\n",
    "        3, 3, num_downs=np.log2(IMG_SIZE).astype(int),\n",
    "        use_dropout=T_DROPOUT, norm_layer=T_norm_layer\n",
    "    ).cuda()\n",
    "    init_weights(T)\n",
    "elif T_TYPE == 'U2Net':\n",
    "    T = U2NET(out_ch=3).cuda()\n",
    "else:\n",
    "    raise NotImplementedError('Unknown T_TYPE: {}'.format(T_TYPE))\n",
    "    \n",
    "if len(DEVICE_IDS) > 1:\n",
    "    T = nn.DataParallel(T, device_ids=DEVICE_IDS)\n",
    "    D = nn.DataParallel(D, device_ids=DEVICE_IDS)\n",
    "    \n",
    "print('T params:', np.sum([np.prod(p.shape) for p in T.parameters()]))\n",
    "print('D params:', np.sum([np.prod(p.shape) for p in D.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0xBADBEEF); np.random.seed(0xBADBEEF)\n",
    "X_fixed, Y_fixed = XY_sampler_plt.sample(10)\n",
    "X_test_fixed, Y_test_fixed = XY_test_sampler_plt.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plot_images(X_fixed, Y_fixed, T)\n",
    "fig, axes = plot_random_paired_images(XY_sampler, T)\n",
    "fig, axes = plot_images(X_test_fixed, Y_test_fixed, T)\n",
    "fig, axes = plot_random_paired_images(XY_test_sampler, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb.init(name=EXP_NAME, project='pairedot', entity='gunsandroses', config=config)\n",
    "\n",
    "wandb.init(project='ICLR GNOT (testing)',\n",
    "    name=EXP_NAME,\n",
    "    entity='rock-and-roll',\n",
    "    reinit=True,\n",
    "    config = config,\n",
    ")\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_opt = torch.optim.Adam(T.parameters(), lr=T_LR, weight_decay=1e-10)\n",
    "D_opt = torch.optim.Adam(D.parameters(), lr=D_LR, weight_decay=1e-10)\n",
    "\n",
    "T_scheduler = torch.optim.lr_scheduler.MultiStepLR(T_opt, milestones=[15000, 30000, 45000, 70000], gamma=0.5)\n",
    "D_scheduler = torch.optim.lr_scheduler.MultiStepLR(D_opt, milestones=[15000, 30000, 45000, 70000], gamma=0.5)\n",
    "\n",
    "if CONTINUE > -1:\n",
    "    T_opt.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, f'T_opt_{SEED}_{CONTINUE}.pt')))\n",
    "    T_scheduler.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, f'T_scheduler_{SEED}_{CONTINUE}.pt')))\n",
    "    T.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, f'T_{SEED}_{CONTINUE}.pt')))\n",
    "    D_opt.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, f'D_opt_{SEED}_{CONTINUE}.pt')))\n",
    "    D.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, f'D_{SEED}_{CONTINUE}.pt')))\n",
    "    D_scheduler.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, f'D_scheduler_{SEED}_{CONTINUE}.pt')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in tqdm(range(CONTINUE+1, MAX_STEPS)):\n",
    "    # T optimization\n",
    "    unfreeze(T); freeze(D)\n",
    "    for t_iter in range(T_ITERS): \n",
    "        T_opt.zero_grad()\n",
    "        X, Y = XY_sampler.sample(BATCH_SIZE)\n",
    "        T_X = T(X)\n",
    "        \n",
    "        if CONDITIONAL:\n",
    "            T_X = torch.cat([T_X, X], dim=1)  \n",
    "            \n",
    "        if COST == 'rmse':\n",
    "            T_loss = (Y-T_X[:, :3]).flatten(start_dim=1).norm(dim=1).mean()\n",
    "        elif COST == 'mse':\n",
    "            T_loss = (Y-T_X[:, :3]).flatten(start_dim=1).square().sum(dim=1).mean()\n",
    "        elif COST == 'mae':\n",
    "            T_loss = (Y-T_X[:, :3]).flatten(start_dim=1).abs().sum(dim=1).mean()\n",
    "        elif COST == 'vgg':\n",
    "            T_loss = vgg_loss(Y, T_X[:, :3]).mean()\n",
    "        else:\n",
    "            raise Exception('Unknown COST')  \n",
    "            \n",
    "        if NOT:\n",
    "            T_loss -= D(T_X).mean()\n",
    "            \n",
    "        T_loss.backward(); T_opt.step()\n",
    "    T_scheduler.step()\n",
    "    del T_loss, T_X, X, Y; gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "    if NOT:\n",
    "        # D optimization\n",
    "        freeze(T); unfreeze(D)\n",
    "        X, _ = XY_sampler.sample(BATCH_SIZE)\n",
    "        with torch.no_grad():\n",
    "            T_X = T(X)\n",
    "        _, Y = XY_sampler.sample(BATCH_SIZE) # We may use the previous batch here\n",
    "        if CONDITIONAL:\n",
    "            with torch.no_grad():\n",
    "                T_X = torch.cat([T_X, X], dim=1)\n",
    "                Y = torch.cat([Y, X], dim=1)\n",
    "        D_opt.zero_grad()\n",
    "        D_loss = D(T_X).mean() - D(Y).mean()\n",
    "        D_loss.backward(); D_opt.step(); D_scheduler.step()\n",
    "        wandb.log({f'D_loss' : D_loss.item()}, step=step) \n",
    "        del D_loss, Y, X, T_X, _; gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "        \n",
    "    if step % PLOT_INTERVAL == 0:\n",
    "        print('Plotting')\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        fig, axes = plot_images(X_fixed, Y_fixed, T)\n",
    "        wandb.log({'Fixed Images' : [wandb.Image(fig2img(fig))]}, step=step) \n",
    "        plt.show(fig); plt.close(fig) \n",
    "        \n",
    "        fig, axes = plot_random_paired_images(XY_sampler_plt, T)\n",
    "        wandb.log({'Random Images' : [wandb.Image(fig2img(fig))]}, step=step) \n",
    "        plt.show(fig); plt.close(fig) \n",
    "        \n",
    "        fig, axes = plot_images(X_test_fixed, Y_test_fixed, T)\n",
    "        wandb.log({'Fixed Test Images' : [wandb.Image(fig2img(fig))]}, step=step) \n",
    "        plt.show(fig); plt.close(fig) \n",
    "        \n",
    "        fig, axes = plot_random_paired_images(XY_test_sampler_plt, T)\n",
    "        wandb.log({'Random Test Images' : [wandb.Image(fig2img(fig))]}, step=step) \n",
    "        plt.show(fig); plt.close(fig) \n",
    "    \n",
    "    \n",
    "    if step % CPKT_INTERVAL == 0:\n",
    "        freeze(T); \n",
    "        torch.save(T.state_dict(), os.path.join(OUTPUT_PATH, f'T_{SEED}_{step}.pt'))\n",
    "        torch.save(D.state_dict(), os.path.join(OUTPUT_PATH, f'D_{SEED}_{step}.pt'))\n",
    "        torch.save(D_opt.state_dict(), os.path.join(OUTPUT_PATH, f'D_opt_{SEED}_{step}.pt'))\n",
    "        torch.save(T_opt.state_dict(), os.path.join(OUTPUT_PATH, f'T_opt_{SEED}_{step}.pt'))\n",
    "        torch.save(D_scheduler.state_dict(), os.path.join(OUTPUT_PATH, f'D_scheduler_{SEED}_{step}.pt'))\n",
    "        torch.save(T_scheduler.state_dict(), os.path.join(OUTPUT_PATH, f'T_scheduler_{SEED}_{step}.pt'))\n",
    "        \n",
    "        \n",
    "        #print('Computing FID')\n",
    "        #mu, sigma = get_pushed_loader_stats(T, XY_test_sampler.loader,  n_epochs=FID_EPOCHS)\n",
    "        #fid = calculate_frechet_distance(mu_data, sigma_data, mu, sigma)\n",
    "        #wandb.log({f'FID (Test)' : fid}, step=step)\n",
    "        #del mu, sigma\n",
    "        \n",
    "\n",
    "    \n",
    "    gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
